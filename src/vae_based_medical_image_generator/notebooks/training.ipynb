{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "def vae_loss(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    kld_regularizer = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + kld_regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Modelling:\n",
    "  def __init__(self, model_type, model, encoder, decoder, hidden_dim, latent_dim, lr, x_dim, optimizer, batch_size, loss, device):\n",
    "    # initialisieren der entsprechenden parameter\n",
    "    self.model_type = model_type\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.latent_dim = latent_dim\n",
    "    self.lr = lr\n",
    "    self.device = device\n",
    "    self.x_dim = x_dim\n",
    "\n",
    "    # Initialize NN instances\n",
    "    self.encoder = encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "    self.decoder = decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n",
    "    self.model = model(Encoder=self.encoder, Decoder=self.decoder, device=device)\n",
    "\n",
    "    # Initialize optimizer and loss\n",
    "    self.optimizer = optimizer(self.model.parameters(), lr=lr)\n",
    "    self.loss = loss\n",
    "\n",
    "    # Initialize variables to persist model performance\n",
    "    self.training_report = list()\n",
    "    # Random noise matrix for testing the decoder net\n",
    "    self.noise_matr = torch.randn(batch_size, latent_dim, ).to(device)\n",
    "\n",
    "  def train(self, train_loader, test_loader, epochs, batch_size):\n",
    "    # Traning Part\n",
    "    self.model.train()\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for epoch in pbar:\n",
    "      \n",
    "      overall_loss = 0\n",
    "      for batch_idx, (x, _) in enumerate(train_loader):\n",
    "          x = x.view(-1, self.x_dim)\n",
    "          x = x.to(self.device)\n",
    "\n",
    "          self.optimizer.zero_grad()\n",
    "\n",
    "          x_hat, mean, log_var = self.model(x)\n",
    "          loss = self.loss(x, x_hat, mean, log_var)\n",
    "\n",
    "          overall_loss += loss.item()\n",
    "          \n",
    "          loss.backward()\n",
    "          self.optimizer.step()\n",
    "      \n",
    "      # Reporting Part\n",
    "      avg_loss = round((overall_loss / (batch_idx*batch_size)),6)\n",
    "      pbar.set_description(f\"Epoch: {epoch + 1}, Average Loss: {avg_loss}\")\n",
    "\n",
    "      # After each use the encoder to transform a sample in the latent space\n",
    "      # and use a noise vector to create a new sample \n",
    "      self.model.eval()\n",
    "\n",
    "      # use one test batch to calculate samples\n",
    "      with torch.no_grad():\n",
    "          for batch_idx, (x, _) in enumerate(test_loader):\n",
    "              x = x.view(-1, self.x_dim)\n",
    "              x = x.to(self.device)\n",
    "              x_hat, mean, log_var = self.model(x)\n",
    "              break\n",
    "          # Use noise data to generate img\n",
    "          generated_images = self.decoder(self.noise_matr)\n",
    "\n",
    "\n",
    "      report_data = {\"epoch\": epoch + 1,\n",
    "                     \"avg_loss\": avg_loss,\n",
    "                     \"sample\": x,\n",
    "                     \"sample_decoded\":x_hat.view(batch_size, int(self.x_dim**.5), int(self.x_dim**.5)),\n",
    "                     \"noise_decoded\": generated_images\n",
    "                     }\n",
    "\n",
    "      self.training_report.append(report_data)  \n",
    "\n",
    "  def create_figs(self, batch_size, every_nth=5):\n",
    "      # Plot the progress of the training process for:\n",
    "      # 1. Decoding a sample image\n",
    "      # 2. Decoding from gaussian noise\n",
    "\n",
    "      h, w = int(self.x_dim**.5), int(self.x_dim**.5)        # for raster image\n",
    "      nrows, ncols = len(self.training_report[::every_nth]), 4  # array of sub-plots\n",
    "      figsize = [10, 2*len(self.training_report[::every_nth])]     # figure size, inches\n",
    "      fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "\n",
    "\n",
    "      samples = self.training_report[0][\"sample\"]\n",
    "      samples = samples.view(batch_size, h, w)\n",
    "      for i, e in enumerate(self.training_report[::every_nth]):\n",
    "        epoch = e[\"epoch\"]\n",
    "        samples_decoded = e[\"sample_decoded\"].view(batch_size, h, w)\n",
    "        noise_decoided = e[\"noise_decoded\"].view(batch_size, h, w)\n",
    "\n",
    "    \n",
    "        ax[i][0].imshow(samples[0].cpu().numpy())\n",
    "        ax[i][0].set_title(\"Sample\")\n",
    "        ax[i][1].imshow(samples_decoded[0].cpu().numpy())\n",
    "        ax[i][1].set_title(f\"Epoch: {epoch}, decoded Sample\")\n",
    "\n",
    "        ax[i][2].imshow(noise_decoided[0].cpu().numpy())\n",
    "        ax[i][2].set_title(f\"Epoch: {epoch}, decoded noise 1\")\n",
    "        ax[i][3].imshow(noise_decoided[1].cpu().numpy())\n",
    "        ax[i][3].set_title(f\"Epoch: {epoch}, decoded noise 2\")\n",
    "\n",
    "      plt.tight_layout(True)\n",
    "      plt.show()\n",
    "\n",
    "      # Plot the progress of the training\n",
    "      x = [epoch[\"epoch\"] for epoch in self.training_report]\n",
    "      y = [epoch[\"avg_loss\"] for epoch in self.training_report]\n",
    "\n",
    "      fig = plt.scatter(x,y)\n",
    "      plt.xlabel(\"Epochs\")\n",
    "      plt.ylabel(\"Average training loss\")\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\LeonDeAndrade\\.medmnist\\organamnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\LeonDeAndrade\\.medmnist\\organamnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Average Loss: -11611.083474: 100%|██████████| 10/10 [01:50<00:00, 11.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from vae_based_medical_image_generator.model.vae import VariationalAutoencoder, EncoderVAE, DecoderVAE\n",
    "from vae_based_medical_image_generator.data import dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "x_dim  = 28**2\n",
    "hidden_dim = 200\n",
    "latent_dim = 2\n",
    "lr = 1e-4\n",
    "epochs = 10\n",
    "optimizer = torch.optim.Adam\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "train_dataset = dataset.load_dataset(dataset_name=\"organamnist\", split=\"train\")\n",
    "test_dataset  = dataset.load_dataset(dataset_name=\"organamnist\", split=\"test\")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "vae_model = Modelling(\"VAE\", VariationalAutoencoder, EncoderVAE, DecoderVAE, hidden_dim, latent_dim, lr, x_dim, optimizer, batch_size, vae_loss, device=\"cpu\")\n",
    "\n",
    "vae_model.train(train_loader, test_loader, epochs, batch_size)\n",
    "\n",
    "# for batch_idx, (x, z) in enumerate(train_loader):\n",
    "#     print(x.view(-1, ).shape)\n",
    "#     print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Modelling' object has no attribute 'create_figs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vae_model\u001b[39m.\u001b[39;49mcreate_figs()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Modelling' object has no attribute 'create_figs'"
     ]
    }
   ],
   "source": [
    "vae_model.create_figs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
